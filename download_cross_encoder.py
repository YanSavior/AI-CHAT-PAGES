#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸‹è½½Cross-Encoderæ¨¡å‹åˆ°Dç›˜
ç¡®ä¿ä¸ä¼šä¸‹è½½åˆ°Cç›˜ç¼“å­˜
"""

import os
import shutil
import time
from transformers import AutoModelForSequenceClassification, AutoTokenizer
import torch

def download_cross_encoder(max_retries=3):
    """ä¸‹è½½Cross-Encoderæ¨¡å‹åˆ°Dç›˜"""
    
    # è®¾ç½®ç›®æ ‡è·¯å¾„
    target_dir = "D:/bge_models/bge-reranker-v2-m3"
    model_name = "BAAI/bge-reranker-v2-m3"
    
    print("ğŸš€ å¼€å§‹ä¸‹è½½Cross-Encoderæ¨¡å‹...")
    print(f"ğŸ“ ç›®æ ‡è·¯å¾„: {target_dir}")
    print(f"ğŸ”— æ¨¡å‹åç§°: {model_name}")
    
    for attempt in range(max_retries):
        try:
            print(f"\nğŸ”„ ç¬¬ {attempt + 1} æ¬¡å°è¯•ä¸‹è½½...")
            
            # åˆ›å»ºç›®æ ‡ç›®å½•
            os.makedirs(target_dir, exist_ok=True)
            print("âœ… ç›®æ ‡ç›®å½•åˆ›å»ºå®Œæˆ")
            
            # è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œå¼ºåˆ¶ä½¿ç”¨Dç›˜ç¼“å­˜
            os.environ['TRANSFORMERS_CACHE'] = 'D:/transformers_cache'
            os.environ['HF_HOME'] = 'D:/huggingface_cache'
            
            print("ğŸ”„ æ­£åœ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶...")
            
            # ä¸‹è½½æ¨¡å‹ï¼ˆå¼ºåˆ¶é‡æ–°ä¸‹è½½ï¼‰
            model = AutoModelForSequenceClassification.from_pretrained(
                model_name,
                cache_dir='D:/transformers_cache',
                local_files_only=False,
                force_download=True
            )
            
            print("ğŸ”„ æ­£åœ¨ä¸‹è½½åˆ†è¯å™¨...")
            
            # ä¸‹è½½åˆ†è¯å™¨ï¼ˆå¼ºåˆ¶é‡æ–°ä¸‹è½½ï¼‰
            tokenizer = AutoTokenizer.from_pretrained(
                model_name,
                cache_dir='D:/transformers_cache',
                local_files_only=False,
                force_download=True
            )
            
            print("âœ… æ¨¡å‹å’Œåˆ†è¯å™¨ä¸‹è½½å®Œæˆ")
            
            # ä¿å­˜åˆ°ç›®æ ‡ç›®å½•
            print("ğŸ”„ æ­£åœ¨ä¿å­˜åˆ°ç›®æ ‡ç›®å½•...")
            model.save_pretrained(target_dir)
            tokenizer.save_pretrained(target_dir)
            
            print("âœ… æ¨¡å‹ä¿å­˜åˆ°ç›®æ ‡ç›®å½•å®Œæˆ")
            
            # éªŒè¯æ–‡ä»¶
            print("ğŸ” éªŒè¯ä¸‹è½½çš„æ–‡ä»¶...")
            files = os.listdir(target_dir)
            print(f"ğŸ“ ç›®æ ‡ç›®å½•ä¸­çš„æ–‡ä»¶: {files}")
            
            # æ£€æŸ¥å…³é”®æ–‡ä»¶ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
            required_files = ['config.json', 'tokenizer.json']
            model_files = ['pytorch_model.bin', 'model.safetensors']
            
            missing_files = []
            
            # æ£€æŸ¥å¿…éœ€æ–‡ä»¶
            for file in required_files:
                if file not in files:
                    missing_files.append(file)
            
            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶ï¼ˆè‡³å°‘éœ€è¦ä¸€ä¸ªï¼‰
            has_model_file = any(model_file in files for model_file in model_files)
            if not has_model_file:
                missing_files.append('æ¨¡å‹æ–‡ä»¶ (pytorch_model.bin æˆ– model.safetensors)')
            
            if missing_files:
                print(f"âš ï¸  ç¼ºå°‘æ–‡ä»¶: {missing_files}")
                raise Exception(f"ç¼ºå°‘å¿…éœ€æ–‡ä»¶: {missing_files}")
            else:
                print("âœ… æ‰€æœ‰å¿…éœ€æ–‡ä»¶éƒ½å·²ä¸‹è½½")
                # æ˜¾ç¤ºå®é™…ä½¿ç”¨çš„æ¨¡å‹æ–‡ä»¶
                actual_model_file = next((f for f in model_files if f in files), None)
                if actual_model_file:
                    print(f"ğŸ“¦ ä½¿ç”¨æ¨¡å‹æ–‡ä»¶: {actual_model_file}")
            
            # æ¸…ç†ç¼“å­˜ç›®å½•
            print("ğŸ§¹ æ¸…ç†ä¸´æ—¶ç¼“å­˜...")
            if os.path.exists('D:/transformers_cache'):
                shutil.rmtree('D:/transformers_cache')
            if os.path.exists('D:/huggingface_cache'):
                shutil.rmtree('D:/huggingface_cache')
            
            print("ğŸ‰ Cross-Encoderæ¨¡å‹ä¸‹è½½å®Œæˆï¼")
            print(f"ğŸ“ æ¨¡å‹ä½ç½®: {target_dir}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {e}")
            
            # æ¸…ç†å¯èƒ½æŸåçš„ç¼“å­˜
            if os.path.exists('D:/transformers_cache'):
                shutil.rmtree('D:/transformers_cache')
            if os.path.exists('D:/huggingface_cache'):
                shutil.rmtree('D:/huggingface_cache')
            
            if attempt < max_retries - 1:
                print(f"â³ ç­‰å¾… 5 ç§’åé‡è¯•...")
                time.sleep(5)
            else:
                print("âŒ æ‰€æœ‰å°è¯•éƒ½å¤±è´¥äº†")
                return False
    
    return False

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("Cross-Encoderæ¨¡å‹ä¸‹è½½å·¥å…·")
    print("=" * 50)
    
    # æ£€æŸ¥ç›®æ ‡ç›®å½•
    target_dir = "D:/bge_models/bge-reranker-v2-m3"
    
    if os.path.exists(target_dir):
        print(f"ğŸ“ ç›®æ ‡ç›®å½•å·²å­˜åœ¨: {target_dir}")
        response = input("æ˜¯å¦ç»§ç»­ä¸‹è½½ï¼Ÿ(y/n): ")
        if response.lower() != 'y':
            print("ä¸‹è½½å·²å–æ¶ˆ")
            return
    
    # å¼€å§‹ä¸‹è½½
    success = download_cross_encoder(max_retries=3)
    
    if success:
        print("\nğŸ‰ ä¸‹è½½æˆåŠŸï¼")
        print("ç°åœ¨å¯ä»¥é‡æ–°å¯åŠ¨RAGç³»ç»Ÿäº†")
    else:
        print("\nâŒ ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("ğŸ’¡ å»ºè®®ï¼š")
        print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦ç¨³å®š")
        print("2. å°è¯•ä½¿ç”¨VPNæˆ–ä»£ç†")
        print("3. æˆ–è€…æ‰‹åŠ¨ä»HuggingFaceç½‘ç«™ä¸‹è½½æ¨¡å‹æ–‡ä»¶")

if __name__ == "__main__":
    main() 